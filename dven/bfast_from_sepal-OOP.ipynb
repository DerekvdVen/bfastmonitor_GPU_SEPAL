{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bfastmonitor CPU using Python\n",
    "## This is bfastmonitor Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The timeseries class is a wrapper for using SEPAL timeseries data with bfast. \n",
      "    It wraps together the data tiles with associated dates files, and their metadata. \n",
      "    It also allows for saving and loading the output rasters. \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from bfast import BFASTMonitor\n",
    "from bfast.utils import crop_data_dates\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sar so extra\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import folium\n",
    "\n",
    "#specific imports\n",
    "from functions import set_output_dir, get_size, get_data_dict\n",
    "\n",
    "# Import the Timeseries class\n",
    "from time_series import Timeseries\n",
    "print(Timeseries.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a time series folder using ipyfilechooser. The standard download location is in downloads/time_series_name/[0,1,2..n]\n",
    "\n",
    "### Optional: select a name for your output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b665c0f82444fdaf71e8b3d00a0735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dven', filename='', title='HTML(value='', layout=Layout(display='none'))', show_hidden…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb21a0e236794eab83c24edad63bfebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='Output storage name:', placeholder='output', style=Descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "path = expanduser(\"~\")\n",
    "\n",
    "def g(directory):\n",
    "    return(directory)\n",
    "                          \n",
    "output_directory_chooser = widgets.interactive(g, \n",
    "                        directory=widgets.Text(description=\"Output storage name:\", \n",
    "                                               style = {'description_width': 'initial'},\n",
    "                                               placeholder = \"output\"))\n",
    "file_chooser = FileChooser(path)\n",
    "\n",
    "display(file_chooser)\n",
    "display(output_directory_chooser)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dven/downloads/Time_series_2020-07-07_11-51-35_Portugal/1/\n",
      "Defaulting to output directory name \"output\" \n"
     ]
    }
   ],
   "source": [
    "timeseries_directory = file_chooser.selected\n",
    "\n",
    "if not timeseries_directory:\n",
    "    raise Exception(\"Please choose a time series directory above with the file selector\")\n",
    "else:\n",
    "    print(timeseries_directory)\n",
    "    set_output_dir(output_directory_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data: if there are tiles in the directory, create a list and load per tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set paths to data\n",
    "dates_path = os.path.join(timeseries_directory, \"dates.csv\")\n",
    "data_list=[]\n",
    "tile_paths = []\n",
    "\n",
    "# check for tiles\n",
    "file_list = os.listdir(timeseries_directory)\n",
    "file_list.sort()\n",
    "for file in file_list:\n",
    "    if file.startswith('tile'):\n",
    "        print(file)\n",
    "        time_series_path =  timeseries_directory + file + \"/\"\n",
    "        tile_paths.append(time_series_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tiles, setting up data as one tile\n"
     ]
    }
   ],
   "source": [
    "# # Set up list of time series tiles and their metadata\n",
    "if not tile_paths:\n",
    "    print(\"No tiles, setting up data as one tile\")\n",
    "    ts_data = Timeseries(timeseries_directory, dates_path)\n",
    "    data_list.append(ts_data)\n",
    "    \n",
    "else:\n",
    "    print(\"Data consists of tiles, setting up tiles in 'data_list' \")\n",
    "    for time_series_path in tile_paths:\n",
    "        ts_data = Timeseries(time_series_path, dates_path)\n",
    "        data_list.append(ts_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some metadata of the created Timeseries class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection:  GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]\n",
      "pixel size:  0.0002694945852358568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timeseries: /home/dven/downloads/Time_series_2020-07-07_11-51-35_Portugal/1/stack.vrt ]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_list = data_list[0:2]\n",
    "#ts_data = data_list[0]\n",
    "print(\"projection: \", data_list[0].projection)\n",
    "print(\"pixel size: \", data_list[0].xpixelsize)\n",
    "#ts_data.log_output_to_txt()\n",
    "\n",
    "data_list = data_list[0:3]\n",
    "data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "k = 3\n",
    "freq = 365\n",
    "trend = True\n",
    "hfrac = 0.25\n",
    "level = 0.05\n",
    "position = (100,100)\n",
    "\n",
    "backend = 'opencl'\n",
    "verbose = 1\n",
    "device_id = 0\n",
    "\n",
    "\n",
    "# start_hist = datetime(2018, 1, 1)\n",
    "# start_monitor = datetime(2019, 1, 1)\n",
    "# end_monitor = datetime(2020, 1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select monitoring period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start monitoring period 2000-03-04 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803dab6ae3094e7fb868e82e3ab83370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionRangeSlider(description='Select the monitoring date range: ', index=(0, 7400), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d9298f06f04d0e83c1ef2446e00d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Start history period:', options=(('2000-03-04', Timestamp('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dates = ts_data.dates\n",
    "start_date = dates[10] # 0 or 10 does not work.. 100 did\n",
    "print(\"start monitoring period\",start_date)\n",
    "end_date = dates[-1]\n",
    "\n",
    "def h(y):\n",
    "    return(y)\n",
    "\n",
    "pandas_dates = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "options =  [(date.strftime('%Y-%m-%d'),date) for date in pandas_dates]\n",
    "index = (0, len(options)-1)\n",
    "\n",
    "\n",
    "monitoring_period = widgets.interactive(h,\n",
    "                                     y=widgets.SelectionRangeSlider(\n",
    "                                            options=options,\n",
    "                                            index=index,\n",
    "                                            description='Select the monitoring date range: ',\n",
    "                                            style = {'description_width': 'initial'},\n",
    "                                            orientation='horizontal',\n",
    "                                            layout={'width': '800px',\"height\":\"50px\"}))\n",
    "\n",
    "\n",
    "history_period = widgets.interactive(h, \n",
    "                                     y=widgets.SelectionSlider(description=\"Start history period:\", \n",
    "                                            options = options,\n",
    "                                            style = {'description_width': 'initial'}))\n",
    "\n",
    "display(monitoring_period)\n",
    "display(history_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start monitor:  2013-11-08 00:00:00\n",
      "end monitor:  2020-06-07 00:00:00\n",
      "start history:  2000-03-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "start_monitor, end_monitor = monitoring_period.result\n",
    "start_hist = history_period.result\n",
    "\n",
    "if history_period.result > start_monitor:\n",
    "    raise Exception(\"Your history period must start before the monitoring period\")\n",
    "\n",
    "#start_monitor = datetime(2013, 10, 30)\n",
    "\n",
    "print(\"start monitor: \", start_monitor)\n",
    "print(\"end monitor: \", end_monitor)\n",
    "print(\"start history: \", start_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over tiles, (or single tile), in data_list\n",
    "### Alternatively, if your means and breaks arrays already exist, skip this code and run load from file in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tile 1 out of 1:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/0.001708984375 [00:00<?, ?it/s]\u001b[A\n",
      "Processing blocks of tile::   0%|          | 0/0.001708984375 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected  openCL, but no device was found, are you sure you set up a gpu session?\n",
      "rastersize:  14 8\n",
      "The natural block size is the block size that is most efficient for accessing the format, gdal found blocksize:  [14, 8]\n",
      "set blocksize explicitly:  256 ,  256\n",
      "bytes required:  473984\n",
      "start monitor:  2013-11-08 00:00:00\n",
      "end monitor:  2020-06-07 00:00:00\n",
      "start history:  2000-03-04 00:00:00\n",
      "0 0 14 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks of tile:: : 1it [00:04,  4.56s/it]                          \n",
      "Processing tile 1 out of 1:   0%|          | 0/1 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Could not access device '0' on platform with '0': clGetPlatformIDs failed: PLATFORM_NOT_FOUND_KHR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bfast/monitor/opencl/base.py\u001b[0m in \u001b[0;36m_init_device\u001b[0;34m(self, platform_id, device_id)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mplatforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyopencl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_platforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplatforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplatform_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLogicError\u001b[0m: clGetPlatformIDs failed: PLATFORM_NOT_FOUND_KHR",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bd997238a434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpbar1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing tile %s out of %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mts_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bfast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_monitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_monitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhfrac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mts_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_block_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_block_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mts_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bfast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mts_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_output_to_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bfastmonitor_cpu/dven/time_series.py\u001b[0m in \u001b[0;36mloop_blocks\u001b[0;34m(self, x_block_size, y_block_size)\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfirst_horstack\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadAsArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                         \u001b[0mbreaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_bfast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                         \u001b[0mbreaks_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mmeans_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bfastmonitor_cpu/dven/time_series.py\u001b[0m in \u001b[0;36mrun_bfast\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m32768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# save breaks and mean magnitudes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bfast/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, dates, n_chunks, nan_value)\u001b[0m\n\u001b[1;32m    163\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                  \u001b[0mplatform_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                  \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 )\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bfast/monitor/opencl/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, start_monitor, freq, k, hfrac, trend, level, detailed_results, old_version, verbose, platform_id, device_id)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# initialize device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplatform_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetailed_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bfast/monitor/opencl/base.py\u001b[0m in \u001b[0;36m_init_device\u001b[0;34m(self, platform_id, device_id)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplatforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplatform_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not access device '{}' on platform with '{}': {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplatform_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Could not access device '0' on platform with '0': clGetPlatformIDs failed: PLATFORM_NOT_FOUND_KHR"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# if you get a memory error, set this lower: 256, 128, 512\n",
    "x_block = y_block = 256\n",
    "\n",
    "\n",
    "with tqdm(total=len(data_list)) as pbar1:\n",
    "        \n",
    "    for counter, ts_data in enumerate(data_list):\n",
    "        pbar1.set_description(\"Processing tile %s out of %s\" % (counter+1, len(data_list)) )\n",
    "        ts_data.set_bfast_parameters(start_monitor,end_monitor,start_hist,freq,k,hfrac,trend,level,backend=backend,verbose=verbose,device_id=device_id)\n",
    "        ts_data.loop_blocks(x_block_size = x_block,y_block_size=y_block)\n",
    "        ts_data.get_bfast_parameters()\n",
    "        ts_data.log_output_to_txt()\n",
    "        ts_data.log_breaks_means_arrays()\n",
    "        pbar1.update(counter)\n",
    "pbar1.close()\n",
    "\n",
    "# add warning for large block size, gets stuck? or so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tiles for output quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tile in data_list:\n",
    "    print(tile.dir)\n",
    "    \n",
    "    # if you want to load in previously saved tiles\n",
    "    #tile.load_breaks_means_arrays_from_file()\n",
    "    \n",
    "    # do some plots\n",
    "    breaks = ts_data.breaks_array\n",
    "    means = ts_data.means_array#.astype(\"int\")\n",
    "    \n",
    "    tile.check_arrays(min_perc_lacking_data = 50)\n",
    "    \n",
    "    #means = means.astype('int')\n",
    "    \n",
    "    plt.hist(breaks)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"breaks datatype: \",breaks.dtype)\n",
    "    print(\"means datatype: \", means.dtype)\n",
    "    im = plt.imshow(means, cmap=plt.cm.OrRd)\n",
    "    plt.colorbar(im);\n",
    "    plt.title('means')\n",
    "    plt.show()\n",
    "    \n",
    "    im = plt.imshow(breaks, cmap=plt.cm.OrRd)\n",
    "    plt.colorbar(im);\n",
    "    plt.title('breaks')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    unique, counts = np.unique(means, return_counts=True)\n",
    "    \n",
    "    print(\"mean counts\")\n",
    "    #print(np.asarray((unique, counts)).T[0:200])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # So this is for merging tiles back together, it seems to work... but need to know for sure.. \n",
    "# # since it does not work in one direction, this one should be correct?\n",
    "\n",
    "# # Make a function to do this\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if len(data_list) > 1:\n",
    "    \n",
    "#     x_locs = []\n",
    "#     y_locs = []\n",
    "#     for tile in data_list:\n",
    "#         loc_index = tile.dir.find(\"tile-\")\n",
    "#         tile_loc = tile.dir[loc_index+5:-1].split(\"-\")\n",
    "#         print(tile_loc)\n",
    "#         if tile_loc[0] not in x_locs:\n",
    "#             x_locs.append(tile_loc[0])\n",
    "#         if tile_loc[1] not in y_locs:\n",
    "#             y_locs.append(tile_loc[1])\n",
    "\n",
    "#     firstx=True\n",
    "#     for tile in data_list:\n",
    "#         for x in x_locs:\n",
    "#             firsty = True\n",
    "\n",
    "#             for y in y_locs:\n",
    "#                 if firsty == True:\n",
    "#                     means_array = tile.means_array\n",
    "#                     small_means_array = tile.means_array[]\n",
    "#                     breaks_array = tile.breaks_array\n",
    "#                     firsty = False\n",
    "#                 else:\n",
    "#                     means_array = np.concatenate((means_array, tile.means_array), axis = 1)\n",
    "#                     breaks_array = np.concatenate((breaks_array, tile.breaks_array), axis = 1)\n",
    "\n",
    "#         if firstx==True:\n",
    "#             big_means_array = means_array\n",
    "#             big_breaks_array = breaks_array     \n",
    "#             firstx=False\n",
    "#         else:\n",
    "#             big_means_array = np.concatenate((big_means_array, means_array),axis = 0)\n",
    "#             big_breaks_array = np.concatenate((big_breaks_array, breaks_array),axis = 0)\n",
    "\n",
    "\n",
    "#     # work on new names, and output bit tile stuff so we only have to do it once\n",
    "    \n",
    "#     arrays_directory = \"output_arrays\"\n",
    "#     if not os.path.exists(\"output_arrays\"):\n",
    "#         os.makedirs(arrays_directory)\n",
    "\n",
    "#     try:\n",
    "#         start_index = save_dir.find(\"Time_series\")\n",
    "#     except:\n",
    "#         start_index = 1\n",
    "    \n",
    "#     save_dir = timeseries_directory.replace(\"/\",\"-\")[start_index:]\n",
    "    \n",
    "    \n",
    "#     save_means_dir = arrays_directory + \"/\" + save_dir + \"_\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + \"_all_means.npy\"\n",
    "#     save_breaks_dir = arrays_directory + \"/\" + save_dir + \"_\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + \"_all_breaks.npy\"\n",
    "#     print(save_means_dir)\n",
    "#     print(save_breaks_dir)\n",
    "#     np.save(save_means_dir, big_means_array)\n",
    "#     np.save(save_breaks_dir, big_breaks_array)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# # for tile in data_list:\n",
    "# #     # regex for the word tile:\n",
    "# #     # then call the numbers col and row\n",
    "# #     # then first loop over cols, then over rows\n",
    "# #     print(tile.dir)\n",
    "# #     namelist.append(tile.dir)\n",
    "# # tile0_0.\n",
    "# #print(namelist.sort())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bfastmonitor() The loop_blocks code runs over smaller blocks, that may be set based on ram space or user itself..?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select negative magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(data_list)>1:\n",
    "    means = big_means_array\n",
    "    breaks = big_breaks_array\n",
    "else:\n",
    "    breaks = ts_data.breaks_array\n",
    "    means = ts_data.means_array\n",
    "\n",
    "plt.imshow(means)\n",
    "plt.show()\n",
    "plt.imshow(breaks)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = data_list[0].means_array\n",
    "breaks = data_list[0].breaks_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# select only negative magnitudes\n",
    "no_breaks_indices = (breaks == -1)\n",
    "means[no_breaks_indices] = 0\n",
    "means[means > 0] = 0 # only want negative mean changes\n",
    "\n",
    "breaks_plot = breaks.astype(np.float)\n",
    "breaks_plot[breaks == -2] = np.nan\n",
    "breaks_plot[breaks == -1] = np.nan\n",
    "breaks_plot[means >= 0] = np.nan\n",
    "\n",
    "# print(\"magnitude change heatmap\")\n",
    "# sns.heatmap(orig_means,  linewidths=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_monitor = []\n",
    "dates = ts_data.dates\n",
    "# collect dates for monitor period\n",
    "for i in range(len(dates)):\n",
    "    if start_monitor <= dates[i]:\n",
    "        dates_monitor.append(dates[i])\n",
    "dates_array = np.array(dates_monitor) # dates_array is the dates that are in the monitoring period\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify output for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_starts = {}\n",
    "\n",
    "# this gives the index of all the data points in the year and after\n",
    "for year in range(start_monitor.year,end_monitor.year+1):\n",
    "    idx_starts[year] = np.argmax((dates_array >= datetime(year, 1, 1)) > False) \n",
    "\n",
    "    breaks_plot_years = copy.deepcopy(breaks_plot)\n",
    "\n",
    "#classifying for plotting\n",
    "ticklist=[]\n",
    "for idx, year in enumerate(idx_starts):\n",
    "    ticklist.append(str(year))\n",
    "    \n",
    "    # if we're at the last year\n",
    "    if idx == len(idx_starts)-1:\n",
    "        breaks_plot_years[np.where(idx_starts[year] < breaks_plot)] = len(idx_starts)-1 \n",
    "        continue\n",
    "    \n",
    "    # if we're at the first year\n",
    "    if idx == 0:\n",
    "        breaks_plot_years[breaks_plot <= idx_starts[year+1]] = 0\n",
    "        continue\n",
    "    \n",
    "    # all other years in between\n",
    "    breaks_plot_years[np.where(np.logical_and(idx_starts[year] < breaks_plot, breaks_plot <= idx_starts[year+1]))] = idx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = len(idx_starts)\n",
    "# from matplotlib.pyplot import figure\n",
    "# figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "cmap = plt.get_cmap(\"rainbow\")\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "bounds = np.linspace(0, bins-1, bins) #third number is the amount of bins in the colorbar 0=0, 6 = ncolors, 7= nyears\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "#norm doesn't work with bins = 2 or less... now the colorbar is ugly, fix it later\n",
    "\n",
    "if bins == 1:\n",
    "    im = axes.imshow(breaks_plot_years,cmap=cmap,vmin=0,vmax=bins)\n",
    "if bins == 2:\n",
    "    im = axes.imshow(breaks_plot_years,cmap=cmap,vmin=0,vmax=bins)\n",
    "else:\n",
    "    im = axes.imshow(breaks_plot_years, cmap=cmap, vmin=0, vmax=bins, norm=norm)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, ticks=range(bins))\n",
    "labels = cbar_ax.set_yticklabels(ticklist)\n",
    "\n",
    "plt.savefig(\"./output/picture.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this doesn't work yet\n",
    "\n",
    "# output_raster = gdal.GetDriverByName('GTiff').Create('myraster.tif',cols, rows, 1 ,gdal.GDT_Float32)  # Open the file\n",
    "\n",
    "# output_raster.SetGeoTransform(geotransform)  # Specify its coordinates\n",
    "# srs = osr.SpatialReference()                 # Establish its coordinate encoding\n",
    "# srs.ImportFromEPSG(4326)                     # This one specifies WGS84 lat long.\n",
    "#                                              # Anyone know how to specify the \n",
    "#                                              # IAU2000:49900 Mars encoding?\n",
    "# output_raster.SetProjection( srs.ExportToWkt() )   # Exports the coordinate system \n",
    "#                                                    # to the file\n",
    "# output_raster.GetRasterBand(1).WriteArray(breaks_plot_years)   # Writes my array to the raster\n",
    "\n",
    "# output_raster.FlushCache()\n",
    "\n",
    "# output_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(breaks_plot_years)\n",
    "breaks_plot_years_norm = 1/(breaks_plot_years + 0.01)\n",
    "print(breaks_plot_years_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap = plt.get_cmap(\"Oranges\")\n",
    "\n",
    "#cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "#cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# viridis = cm.get_cmap('viridis', 12)\n",
    "# print(viridis)\n",
    "# print(viridis(0.56))\n",
    "\n",
    "viridis = cm.get_cmap('rainbow', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "pink = np.array([248/256, 24/256, 148/256, 0])\n",
    "newcolors[:1, :] = pink\n",
    "newcmp = ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latitude)\n",
    "print(xpixelsize)\n",
    "print(cols)\n",
    "print(longitude)\n",
    "print(ypixelsize)\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_data.latitude)\n",
    "print(ts_data.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is probs still wrong\n",
    "\n",
    "from folium.plugins import FloatImage\n",
    "import base64\n",
    "latitude = ts_data.latitude\n",
    "longitude = ts_data.longitude\n",
    "xpixelsize= ts_data.xpixelsize\n",
    "ypixelsize= ts_data.ypixelsize\n",
    "rows = ts_data.nrows\n",
    "cols = ts_data.ncols\n",
    "\n",
    "m = folium.folium.Map(location = (latitude,longitude),tiles = \"Stamen Terrain\",zoom_start=13)\n",
    "\n",
    "# if not all data is \n",
    "#rows = 200\n",
    "#cols = 200\n",
    "\n",
    "\n",
    "# bounds = [[lat_min, lon_min], [lat_max, lon_max]]\n",
    "\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    image=breaks_plot_years_norm,\n",
    "    bounds=[[latitude, longitude], [latitude + (rows*xpixelsize), longitude + (cols*xpixelsize)]],\n",
    "    colormap = newcmp\n",
    ").add_to(m)\n",
    "img = \"output/picture.png\" \n",
    "\n",
    "\n",
    "####\n",
    "resolution, width, height = 75, 4,4\n",
    "encoded = base64.b64encode(open(\"output/picture.png\", 'rb').read()).decode()\n",
    "from folium import IFrame\n",
    "\n",
    "html = '<img src=\"data:image/png;base64,{}\">'.format\n",
    "iframe = IFrame(html(encoded), width=(width*resolution)+20, height=(height*resolution)+20)\n",
    "popup = folium.Popup(iframe, max_width=2650)\n",
    "\n",
    "icon = folium.Icon(color=\"red\", icon=\"ok\")\n",
    "marker = folium.Marker(location=[latitude, longitude], popup=popup, icon=icon)\n",
    "marker.add_to(m)\n",
    "####\n",
    "\n",
    "m.save(os.path.join('output/PortugalBigger_gpu.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
