{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bfastmonitor CPU using Python\n",
    "## This is bfastmonitor Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The timeseries class is a wrapper for using SEPAL timeseries data with bfast. \n",
      "    It wraps together the data tiles with associated dates files, and their metadata. \n",
      "    It also allows for saving and loading the output rasters. \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from bfast import BFASTMonitor\n",
    "from bfast.utils import crop_data_dates\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sar so extra\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import folium\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#specific imports\n",
    "from functions import set_output_dir, get_size, get_data_dict, merge_tiles\n",
    "\n",
    "# Import the Timeseries class\n",
    "from time_series import Timeseries\n",
    "print(Timeseries.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a time series folder using ipyfilechooser. The standard download location is in downloads/time_series_name/[0,1,2..n]\n",
    "\n",
    "### Optional: select a name for your output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af6f5dd68b249ac85e1d06b06f840be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dven', filename='', title='HTML(value='', layout=Layout(display='none'))', show_hidden…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5832b4529c945cf9184981e7ebee748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='Output storage name:', placeholder='output', style=Descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "path = expanduser(\"~\")\n",
    "\n",
    "def g(directory):\n",
    "    return(directory)\n",
    "                          \n",
    "output_directory_chooser = widgets.interactive(g, \n",
    "                        directory=widgets.Text(description=\"Output storage name:\", \n",
    "                                               style = {'description_width': 'initial'},\n",
    "                                               placeholder = \"output\"))\n",
    "file_chooser = FileChooser(path)\n",
    "\n",
    "display(file_chooser)\n",
    "display(output_directory_chooser)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_directory = file_chooser.selected\n",
    "\n",
    "if not timeseries_directory:\n",
    "    raise Exception(\"Please choose a time series directory above with the file selector\")\n",
    "else:\n",
    "    print(timeseries_directory)\n",
    "    set_output_dir(output_directory_chooser)\n",
    "    output_dir = output_directory_chooser.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data: if there are tiles in the directory, create a list and load per tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set paths to data\n",
    "dates_path = os.path.join(timeseries_directory, \"dates.csv\")\n",
    "data_list=[]\n",
    "tile_paths = []\n",
    "\n",
    "# check for tiles\n",
    "file_list = os.listdir(timeseries_directory)\n",
    "file_list.sort()\n",
    "for file in file_list:\n",
    "    if file.startswith('tile'):\n",
    "        print(file)\n",
    "        time_series_path =  timeseries_directory + file + \"/\"\n",
    "        tile_paths.append(time_series_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Set up list of time series tiles and their metadata\n",
    "if not tile_paths:\n",
    "    print(\"No tiles, setting up data as one tile\")\n",
    "    ts_data = Timeseries(timeseries_directory, dates_path)\n",
    "    data_list.append(ts_data)\n",
    "    \n",
    "else:\n",
    "    print(\"Data consists of tiles, setting up tiles in 'data_list' \")\n",
    "    for time_series_path in tile_paths:\n",
    "        ts_data = Timeseries(time_series_path, dates_path)\n",
    "        data_list.append(ts_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some metadata of the created Timeseries class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_list = data_list[0:2]\n",
    "#ts_data = data_list[0]\n",
    "print(\"projection: \", data_list[0].projection)\n",
    "print(\"pixel size: \", data_list[0].xpixelsize)\n",
    "#ts_data.log_output_to_txt()\n",
    "\n",
    "#data_list = data_list[0:6]\n",
    "#data_list = data_list[3:6]\n",
    "data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "k = 3\n",
    "freq = 365\n",
    "trend = True\n",
    "hfrac = 0.25\n",
    "level = 0.05\n",
    "position = (100,100)\n",
    "\n",
    "backend = 'opencl'\n",
    "verbose = 1\n",
    "device_id = 0\n",
    "\n",
    "\n",
    "# start_hist = datetime(2018, 1, 1)\n",
    "# start_monitor = datetime(2019, 1, 1)\n",
    "# end_monitor = datetime(2020, 1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select monitoring period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ts_data.dates\n",
    "start_date = dates[10] # 0 or 10 does not work.. 100 did\n",
    "print(\"start monitoring period\",start_date)\n",
    "end_date = dates[-1]\n",
    "\n",
    "def h(y):\n",
    "    return(y)\n",
    "\n",
    "pandas_dates = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "options =  [(date.strftime('%Y-%m-%d'),date) for date in pandas_dates]\n",
    "index = (0, len(options)-1)\n",
    "\n",
    "\n",
    "monitoring_period = widgets.interactive(h,\n",
    "                                     y=widgets.SelectionRangeSlider(\n",
    "                                            options=options,\n",
    "                                            index=index,\n",
    "                                            description='Select the monitoring date range: ',\n",
    "                                            style = {'description_width': 'initial'},\n",
    "                                            orientation='horizontal',\n",
    "                                            layout={'width': '800px',\"height\":\"50px\"}))\n",
    "\n",
    "\n",
    "history_period = widgets.interactive(h, \n",
    "                                     y=widgets.SelectionSlider(description=\"Start history period:\", \n",
    "                                            options = options,\n",
    "                                            style = {'description_width': 'initial'}))\n",
    "\n",
    "display(monitoring_period)\n",
    "display(history_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_monitor, end_monitor = monitoring_period.result\n",
    "start_hist = history_period.result\n",
    "\n",
    "if history_period.result > start_monitor:\n",
    "    raise Exception(\"Your history period must start before the monitoring period\")\n",
    "\n",
    "start_monitor = datetime(2018, 9, 14)\n",
    "\n",
    "print(\"start monitor: \", start_monitor)\n",
    "print(\"end monitor: \", end_monitor)\n",
    "print(\"start history: \", start_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over tiles, (or single tile), in data_list\n",
    "### Alternatively, if your means and breaks arrays already exist, skip this code and run load from file in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# if you get a memory error, set this lower: 256, 128, 512\n",
    "x_block = y_block = 256\n",
    "\n",
    "# loading bar\n",
    "with tqdm(total=len(data_list)) as pbar1:\n",
    "    \n",
    "    # loop over tile(s) in the data_list\n",
    "    for counter, ts_data in enumerate(data_list):\n",
    "        pbar1.set_description(\"Processing tile %s out of %s\" % (counter+1, len(data_list)) )\n",
    "        \n",
    "        ts_data.set_bfast_parameters(start_monitor,end_monitor,start_hist,freq,k,hfrac,trend,level,backend=backend,verbose=verbose,device_id=device_id)\n",
    "        ts_data.loop_blocks(x_block_size = x_block,y_block_size=y_block)\n",
    "        print(\"##################### \", len(ts_data.cropped_dates), '###############')\n",
    "        ts_data.get_bfast_parameters()\n",
    "        ts_data.log_all_output(output_dir_name=output_dir)\n",
    "        \n",
    "        pbar1.update(counter)\n",
    "pbar1.close()\n",
    "\n",
    "# add warning for large block size, gets stuck? or so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to load tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile in data_list:\n",
    "    print(tile.dir)\n",
    "    \n",
    "    # if you want to load in previously saved tiles\n",
    "    tile.load_breaks_means_arrays_from_file()\n",
    "    tile.start_hist = datetime(2018, 9, 14) # get these from log (automatically?) # probs save a dict as log\n",
    "    tile.end_monitor = datetime(2020, 8, 19) \n",
    "    tile.crop_dates(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tiles for output quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tile in data_list:\n",
    "    print(tile.dir)\n",
    "    \n",
    "    # do some plots\n",
    "    breaks = tile.breaks_array#.astype(\"int\") # it looks like for the new or big data you need to add astype(\"int\") for means\n",
    "    means = tile.means_array#.astype(\"int\")\n",
    "    \n",
    "    tile.check_arrays(min_perc_lacking_data = 50)\n",
    "    \n",
    "    #means = means.astype('int')\n",
    "    \n",
    "    #plt.hist(means)\n",
    "    #plt.show()\n",
    "    \n",
    "    print(\"breaks datatype: \",breaks.dtype)\n",
    "    print(\"means datatype: \", means.dtype)\n",
    "    im = plt.imshow(means, cmap=plt.cm.OrRd)\n",
    "    plt.colorbar(im);\n",
    "    plt.title('means')\n",
    "    plt.show()\n",
    "    \n",
    "    im = plt.imshow(breaks, cmap=plt.cm.OrRd)\n",
    "    plt.colorbar(im);\n",
    "    plt.title('breaks')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #unique, counts = np.unique(means, return_counts=True)\n",
    "    \n",
    "    #print(\"mean counts\")\n",
    "    #print(np.asarray((unique, counts)).T[0:10])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile in data_list:\n",
    "    print(tile.means_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # So this is for merging tiles back together, it seems to work... but need to know for sure.. \n",
    "# # since it does not work in one direction, this one should be correct?\n",
    "\n",
    "\n",
    "\n",
    "if len(data_list) > 1:\n",
    "    \n",
    "    big_means_array, big_breaks_array = merge_tiles(data_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bfastmonitor() The loop_blocks code runs over smaller blocks, that may be set based on ram space or user itself..?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data at once? \n",
    "\n",
    "#     tile.load_breaks_means_arrays_from_file()\n",
    "#     tile.start_hist = datetime(2018, 9, 14) # get these from log (automatically?) # probs save a dict as log\n",
    "#     tile.end_monitor = datetime(2020, 8, 19) \n",
    "#     tile.crop_dates(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select negative magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(data_list)>1:\n",
    "    print(\"tiles\")\n",
    "    means = big_means_array#.astype(\"int\")\n",
    "    breaks = big_breaks_array\n",
    "else:\n",
    "    means = data_list[0].means_array#.astype(\"int\")\n",
    "    breaks = data_list[0].breaks_array\n",
    "plt.imshow(means)\n",
    "plt.show()\n",
    "plt.imshow(breaks)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive and negative\n",
    "\n",
    "#means = data_list[0].means_array\n",
    "#breaks = data_list[0].breaks_array\n",
    "\n",
    "# no_breaks_indices = (breaks == -1)\n",
    "# means[no_breaks_indices] = 0\n",
    "\n",
    "# breaks_plot = breaks.astype(np.float)\n",
    "# breaks_plot[breaks == -2] = np.nan\n",
    "# breaks_plot[breaks == -1] = np.nan\n",
    "# #breaks_plot[means >= 0] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# select only negative magnitudes\n",
    "no_breaks_indices = (breaks == -1)\n",
    "means[no_breaks_indices] = 0\n",
    "means[means > 0] = 0 # only want negative mean changes\n",
    "\n",
    "breaks_plot = breaks.astype(np.float)\n",
    "breaks_plot[breaks == -2] = np.nan\n",
    "breaks_plot[breaks == -1] = np.nan\n",
    "breaks_plot[means >= 0] = np.nan\n",
    "\n",
    "# print(\"magnitude change heatmap\")\n",
    "# sns.heatmap(orig_means,  linewidths=1)\n",
    "\n",
    "plt.imshow(means)\n",
    "plt.show()\n",
    "plt.imshow(breaks)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_monitor = []\n",
    "dates = data_list[0].cropped_dates\n",
    "\n",
    "# collect dates for monitor period\n",
    "for i in range(len(dates)):\n",
    "    if start_monitor <= dates[i]:\n",
    "        dates_monitor.append(dates[i])\n",
    "dates_array = np.array(dates_monitor) # dates_array is the dates that are in the monitoring period\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify output for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_starts = {}\n",
    "\n",
    "# this gives the index of all the data points in the year and after\n",
    "for year in range(start_monitor.year,end_monitor.year+1):\n",
    "    idx_starts[year] = np.argmax((dates_array >= datetime(year, 1, 1)) > False) \n",
    "print(idx_starts)\n",
    "\n",
    "breaks_plot_years = copy.deepcopy(breaks_plot)\n",
    "\n",
    "#classifying for plotting\n",
    "ticklist=[]\n",
    "for idx, year in enumerate(idx_starts):\n",
    "    ticklist.append(str(year))\n",
    "    \n",
    "    # if we're at the last year\n",
    "    if idx == len(idx_starts)-1:\n",
    "        breaks_plot_years[np.where(idx_starts[year] < breaks_plot)] = len(idx_starts)-1 \n",
    "        print(\"last\")\n",
    "        continue\n",
    "    \n",
    "    # if we're at the first year\n",
    "    if idx == 0:\n",
    "        breaks_plot_years[breaks_plot <= idx_starts[year+1]] = 0\n",
    "        print(\"first\")\n",
    "        continue\n",
    "    \n",
    "    # all other years in between\n",
    "    breaks_plot_years[np.where(np.logical_and(idx_starts[year] < breaks_plot, breaks_plot <= idx_starts[year+1]))] = idx\n",
    "    print(\"mid\")\n",
    "\n",
    "unique, counts = np.unique(breaks_plot_years, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = len(idx_starts)\n",
    "# from matplotlib.pyplot import figure\n",
    "# figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "cmap = plt.get_cmap(\"rainbow\")\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "bounds = np.linspace(0, bins-1, bins) #third number is the amount of bins in the colorbar 0=0, 6 = ncolors, 7= nyears\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "print(bins)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(500, 500))\n",
    "\n",
    "#norm doesn't work with bins = 2 or less... now the colorbar is ugly, fix it later\n",
    "\n",
    "if bins == 1:\n",
    "    im = axes.imshow(breaks_plot_years,cmap=cmap,vmin=0,vmax=bins)\n",
    "if bins == 2:\n",
    "    im = axes.imshow(breaks_plot_years,cmap=cmap,vmin=0,vmax=bins)\n",
    "else:\n",
    "    im = axes.imshow(breaks_plot_years, cmap=cmap, vmin=0, vmax=bins, norm=norm)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, ticks=range(bins))\n",
    "labels = cbar_ax.set_yticklabels(ticklist)\n",
    "\n",
    "plt.savefig(\"./output/picture.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(breaks_plot_years)\n",
    "breaks_plot_years_norm = 1/(breaks_plot_years + 0.01)\n",
    "print(breaks_plot_years_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap = plt.get_cmap(\"Oranges\")\n",
    "\n",
    "#cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "#cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# viridis = cm.get_cmap('viridis', 12)\n",
    "# print(viridis)\n",
    "# print(viridis(0.56))\n",
    "\n",
    "viridis = cm.get_cmap('rainbow', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "pink = np.array([248/256, 24/256, 148/256, 0])\n",
    "newcolors[:1, :] = pink\n",
    "newcmp = ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is probs still wrong, maybe not though, we have to plot in a loop, maybe use ipy thing?\n",
    "\n",
    "from folium.plugins import FloatImage\n",
    "import base64\n",
    "latitude = ts_data.latitude\n",
    "longitude = ts_data.longitude\n",
    "xpixelsize= ts_data.xpixelsize\n",
    "ypixelsize= ts_data.ypixelsize\n",
    "rows = ts_data.nrows\n",
    "cols = ts_data.ncols\n",
    "\n",
    "m = folium.folium.Map(location = (latitude,longitude),tiles = \"Stamen Terrain\",zoom_start=13)\n",
    "\n",
    "# if not all data is \n",
    "#rows = 200\n",
    "#cols = 200\n",
    "\n",
    "\n",
    "# bounds = [[lat_min, lon_min], [lat_max, lon_max]]\n",
    "\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    image=breaks_plot_years_norm,\n",
    "    bounds=[[latitude, longitude], [latitude + (rows*xpixelsize), longitude + (cols*xpixelsize)]],\n",
    "    colormap = newcmp\n",
    ").add_to(m)\n",
    "img = \"output/picture.png\" \n",
    "\n",
    "\n",
    "####\n",
    "resolution, width, height = 75, 4,4\n",
    "encoded = base64.b64encode(open(\"output/picture.png\", 'rb').read()).decode()\n",
    "from folium import IFrame\n",
    "\n",
    "html = '<img src=\"data:image/png;base64,{}\">'.format\n",
    "iframe = IFrame(html(encoded), width=(width*resolution)+20, height=(height*resolution)+20)\n",
    "popup = folium.Popup(iframe, max_width=2650)\n",
    "\n",
    "icon = folium.Icon(color=\"red\", icon=\"ok\")\n",
    "marker = folium.Marker(location=[latitude, longitude], popup=popup, icon=icon)\n",
    "marker.add_to(m)\n",
    "####\n",
    "\n",
    "m.save(os.path.join('output/PortugalBigger_gpu.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
